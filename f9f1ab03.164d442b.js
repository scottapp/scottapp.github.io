(window.webpackJsonp=window.webpackJsonp||[]).push([[54],{124:function(e,t,n){"use strict";n.r(t),n.d(t,"frontMatter",(function(){return i})),n.d(t,"metadata",(function(){return l})),n.d(t,"toc",(function(){return c})),n.d(t,"default",(function(){return p}));var a=n(3),r=n(7),o=(n(0),n(129)),i={},l={unversionedId:"ai/docker-Deep-Learning-with-PyTorch-A-60-Minute-Blitz/3-neural_networks_tutorial",id:"ai/docker-Deep-Learning-with-PyTorch-A-60-Minute-Blitz/3-neural_networks_tutorial",isDocsHomePage:!1,title:"3-neural_networks_tutorial",description:"`python",source:"@site/docs/ai/docker-Deep-Learning-with-PyTorch-A-60-Minute-Blitz/3-neural_networks_tutorial.md",slug:"/ai/docker-Deep-Learning-with-PyTorch-A-60-Minute-Blitz/3-neural_networks_tutorial",permalink:"/docs/ai/docker-Deep-Learning-with-PyTorch-A-60-Minute-Blitz/3-neural_networks_tutorial",version:"current",sidebar:"AI",previous:{title:"2-autograd_tutorial",permalink:"/docs/ai/docker-Deep-Learning-with-PyTorch-A-60-Minute-Blitz/2-autograd_tutorial"},next:{title:"4-cifar10_tutorial",permalink:"/docs/ai/docker-Deep-Learning-with-PyTorch-A-60-Minute-Blitz/4-cifar10_tutorial"}},c=[{value:"Define the network",id:"define-the-network",children:[]},{value:"Loss Function",id:"loss-function",children:[]},{value:"Backprop",id:"backprop",children:[]},{value:"Update the weights",id:"update-the-weights",children:[]}],s={toc:c};function p(e){var t=e.components,n=Object(r.a)(e,["components"]);return Object(o.b)("wrapper",Object(a.a)({},s,n,{components:t,mdxType:"MDXLayout"}),Object(o.b)("pre",null,Object(o.b)("code",Object(a.a)({parentName:"pre"},{className:"language-python"}),"%matplotlib inline\n")),Object(o.b)("h1",{id:"neural-networks"},"Neural Networks"),Object(o.b)("p",null,"Neural networks can be constructed using the ",Object(o.b)("inlineCode",{parentName:"p"},"torch.nn")," package."),Object(o.b)("p",null,"Now that you had a glimpse of ",Object(o.b)("inlineCode",{parentName:"p"},"autograd"),", ",Object(o.b)("inlineCode",{parentName:"p"},"nn")," depends on\n",Object(o.b)("inlineCode",{parentName:"p"},"autograd")," to define models and differentiate them.\nAn ",Object(o.b)("inlineCode",{parentName:"p"},"nn.Module")," contains layers, and a method ",Object(o.b)("inlineCode",{parentName:"p"},"forward(input)"),"\\ that\nreturns the ",Object(o.b)("inlineCode",{parentName:"p"},"output"),"."),Object(o.b)("p",null,"For example, look at this network that classifies digit images:"),Object(o.b)("p",null,".. figure:: /_static/img/mnist.png\n:alt: convnet"),Object(o.b)("p",null,"   convnet"),Object(o.b)("p",null,"It is a simple feed-forward network. It takes the input, feeds it\nthrough several layers one after the other, and then finally gives the\noutput."),Object(o.b)("p",null,"A typical training procedure for a neural network is as follows:"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"Define the neural network that has some learnable parameters (or\nweights)"),Object(o.b)("li",{parentName:"ul"},"Iterate over a dataset of inputs"),Object(o.b)("li",{parentName:"ul"},"Process input through the network"),Object(o.b)("li",{parentName:"ul"},"Compute the loss (how far is the output from being correct)"),Object(o.b)("li",{parentName:"ul"},"Propagate gradients back into the network\u2019s parameters"),Object(o.b)("li",{parentName:"ul"},"Update the weights of the network, typically using a simple update rule:\n",Object(o.b)("inlineCode",{parentName:"li"},"weight = weight - learning_rate * gradient"))),Object(o.b)("h2",{id:"define-the-network"},"Define the network"),Object(o.b)("p",null,"Let\u2019s define this network:"),Object(o.b)("pre",null,Object(o.b)("code",Object(a.a)({parentName:"pre"},{className:"language-python"}),"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Net(nn.Module):\n\n    def __init__(self):\n        super(Net, self).__init__()\n        # 1 input image channel, 6 output channels, 3x3 square convolution\n        # kernel\n        self.conv1 = nn.Conv2d(1, 6, 3)\n        self.conv2 = nn.Conv2d(6, 16, 3)\n        # an affine operation: y = Wx + b\n        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension \n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        # Max pooling over a (2, 2) window\n        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n        # If the size is a square you can only specify a single number\n        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n        x = x.view(-1, self.num_flat_features(x))\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n    def num_flat_features(self, x):\n        size = x.size()[1:]  # all dimensions except the batch dimension\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features\n\n\nnet = Net()\nprint(net)\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(a.a)({parentName:"pre"},{}),"Net(\n  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n  (fc1): Linear(in_features=576, out_features=120, bias=True)\n  (fc2): Linear(in_features=120, out_features=84, bias=True)\n  (fc3): Linear(in_features=84, out_features=10, bias=True)\n)\n")),Object(o.b)("p",null,"You just have to define the ",Object(o.b)("inlineCode",{parentName:"p"},"forward")," function, and the ",Object(o.b)("inlineCode",{parentName:"p"},"backward"),"\nfunction (where gradients are computed) is automatically defined for you\nusing ",Object(o.b)("inlineCode",{parentName:"p"},"autograd"),".\nYou can use any of the Tensor operations in the ",Object(o.b)("inlineCode",{parentName:"p"},"forward")," function."),Object(o.b)("p",null,"The learnable parameters of a model are returned by ",Object(o.b)("inlineCode",{parentName:"p"},"net.parameters()")),Object(o.b)("pre",null,Object(o.b)("code",Object(a.a)({parentName:"pre"},{className:"language-python"}),"params = list(net.parameters())\nprint(len(params))\nprint(params[0].size())  # conv1's .weight\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(a.a)({parentName:"pre"},{}),"10\ntorch.Size([6, 1, 3, 3])\n")),Object(o.b)("p",null,"Let's try a random 32x32 input.\nNote: expected input size of this net (LeNet) is 32x32. To use this net on\nthe MNIST dataset, please resize the images from the dataset to 32x32."),Object(o.b)("pre",null,Object(o.b)("code",Object(a.a)({parentName:"pre"},{className:"language-python"}),"input = torch.randn(1, 1, 32, 32)\nout = net(input)\nprint(out)\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(a.a)({parentName:"pre"},{}),"tensor([[-0.1342, -0.0333, -0.1572,  0.0799, -0.0239,  0.0030,  0.0311,  0.1129,\n          0.0043,  0.0839]], grad_fn=<AddmmBackward>)\n")),Object(o.b)("p",null,"Zero the gradient buffers of all parameters and backprops with random\ngradients:"),Object(o.b)("pre",null,Object(o.b)("code",Object(a.a)({parentName:"pre"},{className:"language-python"}),"net.zero_grad()\nout.backward(torch.randn(1, 10))\n")),Object(o.b)("p",null,"Before proceeding further, let's recap all the classes you\u2019ve seen so far."),Object(o.b)("p",null,Object(o.b)("strong",{parentName:"p"},"Recap:")),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},Object(o.b)("inlineCode",{parentName:"li"},"torch.Tensor")," - A ",Object(o.b)("em",{parentName:"li"},"multi-dimensional array")," with support for autograd\noperations like ",Object(o.b)("inlineCode",{parentName:"li"},"backward()"),". Also ",Object(o.b)("em",{parentName:"li"},"holds the gradient")," w.r.t. the\ntensor."),Object(o.b)("li",{parentName:"ul"},Object(o.b)("inlineCode",{parentName:"li"},"nn.Module")," - Neural network module. ",Object(o.b)("em",{parentName:"li"},"Convenient way of\nencapsulating parameters"),", with helpers for moving them to GPU,\nexporting, loading, etc."),Object(o.b)("li",{parentName:"ul"},Object(o.b)("inlineCode",{parentName:"li"},"nn.Parameter")," - A kind of Tensor, that is ",Object(o.b)("em",{parentName:"li"},"automatically\nregistered as a parameter when assigned as an attribute to a"),Object(o.b)("inlineCode",{parentName:"li"},"Module"),"."),Object(o.b)("li",{parentName:"ul"},Object(o.b)("inlineCode",{parentName:"li"},"autograd.Function")," - Implements ",Object(o.b)("em",{parentName:"li"},"forward and backward definitions\nof an autograd operation"),". Every ",Object(o.b)("inlineCode",{parentName:"li"},"Tensor")," operation creates at\nleast a single ",Object(o.b)("inlineCode",{parentName:"li"},"Function")," node that connects to functions that\ncreated a ",Object(o.b)("inlineCode",{parentName:"li"},"Tensor")," and ",Object(o.b)("em",{parentName:"li"},"encodes its history"),".")),Object(o.b)("p",null,Object(o.b)("strong",{parentName:"p"},"At this point, we covered:")),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"Defining a neural network"),Object(o.b)("li",{parentName:"ul"},"Processing inputs and calling backward")),Object(o.b)("p",null,Object(o.b)("strong",{parentName:"p"},"Still Left:")),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"Computing the loss"),Object(o.b)("li",{parentName:"ul"},"Updating the weights of the network")),Object(o.b)("h2",{id:"loss-function"},"Loss Function"),Object(o.b)("p",null,"A loss function takes the (output, target) pair of inputs, and computes a\nvalue that estimates how far away the output is from the target."),Object(o.b)("p",null,"There are several different\n",Object(o.b)("inlineCode",{parentName:"p"},"loss functions <https://pytorch.org/docs/nn.html#loss-functions>"),"_ under the\nnn package .\nA simple loss is: ",Object(o.b)("inlineCode",{parentName:"p"},"nn.MSELoss")," which computes the mean-squared error\nbetween the input and the target."),Object(o.b)("p",null,"For example:"),Object(o.b)("pre",null,Object(o.b)("code",Object(a.a)({parentName:"pre"},{className:"language-python"}),"output = net(input)\ntarget = torch.randn(10)  # a dummy target, for example\ntarget = target.view(1, -1)  # make it the same shape as output\ncriterion = nn.MSELoss()\n\nloss = criterion(output, target)\nprint(loss)\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(a.a)({parentName:"pre"},{}),"tensor(0.8655, grad_fn=<MseLossBackward>)\n")),Object(o.b)("p",null,"Now, if you follow ",Object(o.b)("inlineCode",{parentName:"p"},"loss")," in the backward direction, using its\n",Object(o.b)("inlineCode",{parentName:"p"},".grad_fn")," attribute, you will see a graph of computations that looks\nlike this:"),Object(o.b)("p",null,"::"),Object(o.b)("pre",null,Object(o.b)("code",Object(a.a)({parentName:"pre"},{}),"input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n      -> view -> linear -> relu -> linear -> relu -> linear\n      -> MSELoss\n      -> loss\n")),Object(o.b)("p",null,"So, when we call ",Object(o.b)("inlineCode",{parentName:"p"},"loss.backward()"),", the whole graph is differentiated\nw.r.t. the loss, and all Tensors in the graph that has ",Object(o.b)("inlineCode",{parentName:"p"},"requires_grad=True"),"\nwill have their ",Object(o.b)("inlineCode",{parentName:"p"},".grad")," Tensor accumulated with the gradient."),Object(o.b)("p",null,"For illustration, let us follow a few steps backward:"),Object(o.b)("pre",null,Object(o.b)("code",Object(a.a)({parentName:"pre"},{className:"language-python"}),"print(loss.grad_fn)  # MSELoss\nprint(loss.grad_fn.next_functions[0][0])  # Linear\nprint(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(a.a)({parentName:"pre"},{}),"<MseLossBackward object at 0x7f108cfc5a90>\n<AddmmBackward object at 0x7f108cfc5a90>\n<AccumulateGrad object at 0x7f108d22f8d0>\n")),Object(o.b)("h2",{id:"backprop"},"Backprop"),Object(o.b)("p",null,"To backpropagate the error all we have to do is to ",Object(o.b)("inlineCode",{parentName:"p"},"loss.backward()"),".\nYou need to clear the existing gradients though, else gradients will be\naccumulated to existing gradients."),Object(o.b)("p",null,"Now we shall call ",Object(o.b)("inlineCode",{parentName:"p"},"loss.backward()"),", and have a look at conv1's bias\ngradients before and after the backward."),Object(o.b)("pre",null,Object(o.b)("code",Object(a.a)({parentName:"pre"},{className:"language-python"}),"net.zero_grad()     # zeroes the gradient buffers of all parameters\n\nprint('conv1.bias.grad before backward')\nprint(net.conv1.bias.grad)\n\nloss.backward()\n\nprint('conv1.bias.grad after backward')\nprint(net.conv1.bias.grad)\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(a.a)({parentName:"pre"},{}),"conv1.bias.grad before backward\ntensor([0., 0., 0., 0., 0., 0.])\nconv1.bias.grad after backward\ntensor([ 0.0353,  0.0197, -0.0259,  0.0053, -0.0409, -0.0251])\n")),Object(o.b)("p",null,"Now, we have seen how to use loss functions."),Object(o.b)("p",null,Object(o.b)("strong",{parentName:"p"},"Read Later:")),Object(o.b)("p",null,"  The neural network package contains various modules and loss functions\nthat form the building blocks of deep neural networks. A full list with\ndocumentation is ",Object(o.b)("inlineCode",{parentName:"p"},"here <https://pytorch.org/docs/nn>"),"_."),Object(o.b)("p",null,Object(o.b)("strong",{parentName:"p"},"The only thing left to learn is:")),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"Updating the weights of the network")),Object(o.b)("h2",{id:"update-the-weights"},"Update the weights"),Object(o.b)("p",null,"The simplest update rule used in practice is the Stochastic Gradient\nDescent (SGD):"),Object(o.b)("pre",null,Object(o.b)("code",Object(a.a)({parentName:"pre"},{})," ``weight = weight - learning_rate * gradient``\n")),Object(o.b)("p",null,"We can implement this using simple Python code:"),Object(o.b)("p",null,".. code:: python"),Object(o.b)("pre",null,Object(o.b)("code",Object(a.a)({parentName:"pre"},{}),"learning_rate = 0.01\nfor f in net.parameters():\n    f.data.sub_(f.grad.data * learning_rate)\n")),Object(o.b)("p",null,"However, as you use neural networks, you want to use various different\nupdate rules such as SGD, Nesterov-SGD, Adam, RMSProp, etc.\nTo enable this, we built a small package: ",Object(o.b)("inlineCode",{parentName:"p"},"torch.optim")," that\nimplements all these methods. Using it is very simple:"),Object(o.b)("pre",null,Object(o.b)("code",Object(a.a)({parentName:"pre"},{className:"language-python"}),"import torch.optim as optim\n\n# create your optimizer\noptimizer = optim.SGD(net.parameters(), lr=0.01)\n\n# in your training loop:\noptimizer.zero_grad()   # zero the gradient buffers\noutput = net(input)\nloss = criterion(output, target)\nloss.backward()\noptimizer.step()    # Does the update\n")),Object(o.b)("p",null,".. Note::"),Object(o.b)("pre",null,Object(o.b)("code",Object(a.a)({parentName:"pre"},{}),"  Observe how gradient buffers had to be manually set to zero using\n  ``optimizer.zero_grad()``. This is because gradients are accumulated\n  as explained in the `Backprop`_ section.\n")))}p.isMDXComponent=!0},129:function(e,t,n){"use strict";n.d(t,"a",(function(){return b})),n.d(t,"b",(function(){return m}));var a=n(0),r=n.n(a);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function c(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=r.a.createContext({}),p=function(e){var t=r.a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},b=function(e){var t=p(e.components);return r.a.createElement(s.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return r.a.createElement(r.a.Fragment,{},t)}},d=r.a.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,i=e.parentName,s=c(e,["components","mdxType","originalType","parentName"]),b=p(n),d=a,m=b["".concat(i,".").concat(d)]||b[d]||u[d]||o;return n?r.a.createElement(m,l(l({ref:t},s),{},{components:n})):r.a.createElement(m,l({ref:t},s))}));function m(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,i=new Array(o);i[0]=d;var l={};for(var c in t)hasOwnProperty.call(t,c)&&(l[c]=t[c]);l.originalType=e,l.mdxType="string"==typeof e?e:a,i[1]=l;for(var s=2;s<o;s++)i[s]=n[s];return r.a.createElement.apply(null,i)}return r.a.createElement.apply(null,n)}d.displayName="MDXCreateElement"}}]);