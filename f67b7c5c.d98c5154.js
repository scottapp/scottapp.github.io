(window.webpackJsonp=window.webpackJsonp||[]).push([[53],{123:function(e,t,a){"use strict";a.r(t),a.d(t,"frontMatter",(function(){return o})),a.d(t,"metadata",(function(){return i})),a.d(t,"toc",(function(){return p})),a.d(t,"default",(function(){return u}));var n=a(3),r=a(7),c=(a(0),a(129)),o={title:"305 Batch Train"},i={unversionedId:"ai/Docker-PyTorch-Tutorial/305_batch_train",id:"ai/Docker-PyTorch-Tutorial/305_batch_train",isDocsHomePage:!1,title:"305 Batch Train",description:"View more, visit my tutorial page//mofanpy.com/tutorials/",source:"@site/docs/ai/Docker-PyTorch-Tutorial/305_batch_train.md",slug:"/ai/Docker-PyTorch-Tutorial/305_batch_train",permalink:"/docs/ai/Docker-PyTorch-Tutorial/305_batch_train",version:"current",sidebar:"AI",previous:{title:"304 Save and Reload",permalink:"/docs/ai/Docker-PyTorch-Tutorial/304_save_reload"},next:{title:"206 Optimizers",permalink:"/docs/ai/Docker-PyTorch-Tutorial/306_optimizer"}},p=[{value:"Suppose a different batch size that cannot be fully divided by the number of data entreis:",id:"suppose-a-different-batch-size-that-cannot-be-fully-divided-by-the-number-of-data-entreis",children:[]}],b={toc:p};function u(e){var t=e.components,a=Object(r.a)(e,["components"]);return Object(c.b)("wrapper",Object(n.a)({},b,a,{components:t,mdxType:"MDXLayout"}),Object(c.b)("p",null,"View more, visit my tutorial page: ",Object(c.b)("a",Object(n.a)({parentName:"p"},{href:"https://mofanpy.com/tutorials/"}),"https://mofanpy.com/tutorials/"),"\nMy Youtube Channel: ",Object(c.b)("a",Object(n.a)({parentName:"p"},{href:"https://www.youtube.com/user/MorvanZhou"}),"https://www.youtube.com/user/MorvanZhou")),Object(c.b)("p",null,"Dependencies:"),Object(c.b)("ul",null,Object(c.b)("li",{parentName:"ul"},"torch: 0.1.11")),Object(c.b)("pre",null,Object(c.b)("code",Object(n.a)({parentName:"pre"},{className:"language-python"}),"import torch\nimport torch.utils.data as Data\n\ntorch.manual_seed(1)    # reproducible\n")),Object(c.b)("pre",null,Object(c.b)("code",Object(n.a)({parentName:"pre"},{}),"<torch._C.Generator at 0x7faffc159918>\n")),Object(c.b)("pre",null,Object(c.b)("code",Object(n.a)({parentName:"pre"},{className:"language-python"}),"BATCH_SIZE = 5\n# BATCH_SIZE = 8\n")),Object(c.b)("pre",null,Object(c.b)("code",Object(n.a)({parentName:"pre"},{className:"language-python"}),"x = torch.linspace(1, 10, 10)       # this is x data (torch tensor)\ny = torch.linspace(10, 1, 10)       # this is y data (torch tensor)\n\n")),Object(c.b)("pre",null,Object(c.b)("code",Object(n.a)({parentName:"pre"},{className:"language-python"}),"torch_dataset = Data.TensorDataset(data_tensor=x, target_tensor=y)\nloader = Data.DataLoader(\n    dataset=torch_dataset,      # torch TensorDataset format\n    batch_size=BATCH_SIZE,      # mini batch size\n    shuffle=True,               # random shuffle for training\n    num_workers=2,              # subprocesses for loading data\n)\n")),Object(c.b)("pre",null,Object(c.b)("code",Object(n.a)({parentName:"pre"},{className:"language-python"}),"for epoch in range(3):   # train entire dataset 3 times\n    for step, (batch_x, batch_y) in enumerate(loader):  # for each training step\n        # train your data...\n        print('Epoch: ', epoch, '| Step: ', step, '| batch x: ',\n              batch_x.numpy(), '| batch y: ', batch_y.numpy())\n\n")),Object(c.b)("pre",null,Object(c.b)("code",Object(n.a)({parentName:"pre"},{}),"Epoch:  0 | Step:  0 | batch x:  [ 6.  7.  2.  3.  1.] | batch y:  [  5.   4.   9.   8.  10.]\nEpoch:  0 | Step:  1 | batch x:  [  9.  10.   4.   8.   5.] | batch y:  [ 2.  1.  7.  3.  6.]\nEpoch:  1 | Step:  0 | batch x:  [  3.   4.   2.   9.  10.] | batch y:  [ 8.  7.  9.  2.  1.]\nEpoch:  1 | Step:  1 | batch x:  [ 1.  7.  8.  5.  6.] | batch y:  [ 10.   4.   3.   6.   5.]\nEpoch:  2 | Step:  0 | batch x:  [ 3.  9.  2.  6.  7.] | batch y:  [ 8.  2.  9.  5.  4.]\nEpoch:  2 | Step:  1 | batch x:  [ 10.   4.   8.   1.   5.] | batch y:  [  1.   7.   3.  10.   6.]\n")),Object(c.b)("h3",{id:"suppose-a-different-batch-size-that-cannot-be-fully-divided-by-the-number-of-data-entreis"},"Suppose a different batch size that cannot be fully divided by the number of data entreis:"),Object(c.b)("pre",null,Object(c.b)("code",Object(n.a)({parentName:"pre"},{className:"language-python"}),"BATCH_SIZE = 8\nloader = Data.DataLoader(\n    dataset=torch_dataset,      # torch TensorDataset format\n    batch_size=BATCH_SIZE,      # mini batch size\n    shuffle=True,               # random shuffle for training\n    num_workers=2,              # subprocesses for loading data\n)\nfor epoch in range(3):   # train entire dataset 3 times\n    for step, (batch_x, batch_y) in enumerate(loader):  # for each training step\n        # train your data...\n        print('Epoch: ', epoch, '| Step: ', step, '| batch x: ',\n              batch_x.numpy(), '| batch y: ', batch_y.numpy())\n")),Object(c.b)("pre",null,Object(c.b)("code",Object(n.a)({parentName:"pre"},{}),"Epoch:  0 | Step:  0 | batch x:  [  3.  10.   9.   4.   7.   8.   2.   1.] | batch y:  [  8.   1.   2.   7.   4.   3.   9.  10.]\nEpoch:  0 | Step:  1 | batch x:  [ 5.  6.] | batch y:  [ 6.  5.]\nEpoch:  1 | Step:  0 | batch x:  [  4.   8.   3.   2.   1.  10.   5.   6.] | batch y:  [  7.   3.   8.   9.  10.   1.   6.   5.]\nEpoch:  1 | Step:  1 | batch x:  [ 7.  9.] | batch y:  [ 4.  2.]\nEpoch:  2 | Step:  0 | batch x:  [  6.   2.   4.  10.   9.   3.   8.   5.] | batch y:  [ 5.  9.  7.  1.  2.  8.  3.  6.]\nEpoch:  2 | Step:  1 | batch x:  [ 7.  1.] | batch y:  [  4.  10.]\n")),Object(c.b)("pre",null,Object(c.b)("code",Object(n.a)({parentName:"pre"},{className:"language-python"}),"")))}u.isMDXComponent=!0},129:function(e,t,a){"use strict";a.d(t,"a",(function(){return s})),a.d(t,"b",(function(){return d}));var n=a(0),r=a.n(n);function c(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){c(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function p(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},c=Object.keys(e);for(n=0;n<c.length;n++)a=c[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var c=Object.getOwnPropertySymbols(e);for(n=0;n<c.length;n++)a=c[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var b=r.a.createContext({}),u=function(e){var t=r.a.useContext(b),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},s=function(e){var t=u(e.components);return r.a.createElement(b.Provider,{value:t},e.children)},l={inlineCode:"code",wrapper:function(e){var t=e.children;return r.a.createElement(r.a.Fragment,{},t)}},h=r.a.forwardRef((function(e,t){var a=e.components,n=e.mdxType,c=e.originalType,o=e.parentName,b=p(e,["components","mdxType","originalType","parentName"]),s=u(a),h=n,d=s["".concat(o,".").concat(h)]||s[h]||l[h]||c;return a?r.a.createElement(d,i(i({ref:t},b),{},{components:a})):r.a.createElement(d,i({ref:t},b))}));function d(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var c=a.length,o=new Array(c);o[0]=h;var i={};for(var p in t)hasOwnProperty.call(t,p)&&(i[p]=t[p]);i.originalType=e,i.mdxType="string"==typeof e?e:n,o[1]=i;for(var b=2;b<c;b++)o[b]=a[b];return r.a.createElement.apply(null,o)}return r.a.createElement.apply(null,a)}h.displayName="MDXCreateElement"}}]);