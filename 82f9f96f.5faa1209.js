(window.webpackJsonp=window.webpackJsonp||[]).push([[26],{127:function(e,t,n){"use strict";n.d(t,"a",(function(){return s})),n.d(t,"b",(function(){return O}));var r=n(0),a=n.n(r);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function c(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function p(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?c(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):c(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function b(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var l=a.a.createContext({}),u=function(e){var t=a.a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):p(p({},t),e)),n},s=function(e){var t=u(e.components);return a.a.createElement(l.Provider,{value:t},e.children)},i={inlineCode:"code",wrapper:function(e){var t=e.children;return a.a.createElement(a.a.Fragment,{},t)}},m=a.a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,c=e.parentName,l=b(e,["components","mdxType","originalType","parentName"]),s=u(n),m=r,O=s["".concat(c,".").concat(m)]||s[m]||i[m]||o;return n?a.a.createElement(O,p(p({ref:t},l),{},{components:n})):a.a.createElement(O,p({ref:t},l))}));function O(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,c=new Array(o);c[0]=m;var p={};for(var b in t)hasOwnProperty.call(t,b)&&(p[b]=t[b]);p.originalType=e,p.mdxType="string"==typeof e?e:r,c[1]=p;for(var l=2;l<o;l++)c[l]=n[l];return a.a.createElement.apply(null,c)}return a.a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},97:function(e,t,n){"use strict";n.r(t),n.d(t,"frontMatter",(function(){return c})),n.d(t,"metadata",(function(){return p})),n.d(t,"toc",(function(){return b})),n.d(t,"default",(function(){return u}));var r=n(3),a=n(7),o=(n(0),n(127)),c={title:"201 Torch and Numpy"},p={unversionedId:"ai/Docker-PyTorch-Tutorial/201_torch_numpy",id:"ai/Docker-PyTorch-Tutorial/201_torch_numpy",isDocsHomePage:!1,title:"201 Torch and Numpy",description:"View more, visit my tutorial page//mofanpy.com/tutorials/",source:"@site/docs/ai/Docker-PyTorch-Tutorial/201_torch_numpy.md",slug:"/ai/Docker-PyTorch-Tutorial/201_torch_numpy",permalink:"/docs/ai/Docker-PyTorch-Tutorial/201_torch_numpy",version:"current",sidebar:"AI",previous:{title:"Pytorch Tutorial",permalink:"/docs/ai/Docker-PyTorch-Tutorial"},next:{title:"202 Variable",permalink:"/docs/ai/Docker-PyTorch-Tutorial/202_variable"}},b=[],l={toc:b};function u(e){var t=e.components,n=Object(a.a)(e,["components"]);return Object(o.b)("wrapper",Object(r.a)({},l,n,{components:t,mdxType:"MDXLayout"}),Object(o.b)("p",null,"View more, visit my tutorial page: ",Object(o.b)("a",Object(r.a)({parentName:"p"},{href:"https://mofanpy.com/tutorials/"}),"https://mofanpy.com/tutorials/"),"\nMy Youtube Channel: ",Object(o.b)("a",Object(r.a)({parentName:"p"},{href:"https://www.youtube.com/user/MorvanZhou"}),"https://www.youtube.com/user/MorvanZhou")),Object(o.b)("p",null,"Dependencies:"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"torch: 0.1.11"),Object(o.b)("li",{parentName:"ul"},"numpy")),Object(o.b)("p",null,"Details about math operation in torch can be found in: ",Object(o.b)("a",Object(r.a)({parentName:"p"},{href:"http://pytorch.org/docs/torch.html#math-operations"}),"http://pytorch.org/docs/torch.html#math-operations")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"import torch\nimport numpy as np\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"# convert numpy to tensor or vise versa\nnp_data = np.arange(6).reshape((2, 3))\ntorch_data = torch.from_numpy(np_data)\ntensor2array = torch_data.numpy()\nprint(\n    '\\nnumpy array:', np_data,          # [[0 1 2], [3 4 5]]\n    '\\ntorch tensor:', torch_data,      #  0  1  2 \\n 3  4  5    [torch.LongTensor of size 2x3]\n    '\\ntensor to array:', tensor2array, # [[0 1 2], [3 4 5]]\n)\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{}),"numpy array: [[0 1 2]\n [3 4 5]] \ntorch tensor: tensor([[ 0,  1,  2],\n        [ 3,  4,  5]], dtype=torch.int32) \ntensor to array: [[0 1 2]\n [3 4 5]]\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"# abs\ndata = [-1, -2, 1, 2]\ntensor = torch.FloatTensor(data)  # 32-bit floating point\nprint(\n    '\\nabs',\n    '\\nnumpy: ', np.abs(data),          # [1 2 1 2]\n    '\\ntorch: ', torch.abs(tensor)      # [1 2 1 2]\n)\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{}),"abs \nnumpy:  [1 2 1 2] \ntorch:  tensor([ 1.,  2.,  1.,  2.])\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"tensor.abs()\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{}),"tensor([ 1.,  2.,  1.,  2.])\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"# sin\nprint(\n    '\\nsin',\n    '\\nnumpy: ', np.sin(data),      # [-0.84147098 -0.90929743  0.84147098  0.90929743]\n    '\\ntorch: ', torch.sin(tensor)  # [-0.8415 -0.9093  0.8415  0.9093]\n)\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{}),"sin \nnumpy:  [-0.84147098 -0.90929743  0.84147098  0.90929743] \ntorch:  tensor([-0.8415, -0.9093,  0.8415,  0.9093])\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"tensor.sigmoid()\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{}),"tensor([ 0.2689,  0.1192,  0.7311,  0.8808])\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"tensor.exp()\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{}),"tensor([ 0.3679,  0.1353,  2.7183,  7.3891])\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"# mean\nprint(\n    '\\nmean',\n    '\\nnumpy: ', np.mean(data),         # 0.0\n    '\\ntorch: ', torch.mean(tensor)     # 0.0\n)\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{}),"mean \nnumpy:  0.0 \ntorch:  tensor(0.)\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"# matrix multiplication\ndata = [[1,2], [3,4]]\ntensor = torch.FloatTensor(data)  # 32-bit floating point\n# correct method\nprint(\n    '\\nmatrix multiplication (matmul)',\n    '\\nnumpy: ', np.matmul(data, data),     # [[7, 10], [15, 22]]\n    '\\ntorch: ', torch.mm(tensor, tensor)   # [[7, 10], [15, 22]]\n)\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{}),"matrix multiplication (matmul) \nnumpy:  [[ 7 10]\n [15 22]] \ntorch:  tensor([[ 7., 10.],\n        [15., 22.]])\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"# incorrect method\ndata = np.array(data)\ntensor = torch.Tensor(data)\nprint(\n    '\\nmatrix multiplication (dot)',\n    '\\nnumpy: ', data.dot(data),        # [[7, 10], [15, 22]]\n    '\\ntorch: ', torch.dot(tensor.dot(tensor))     # NOT WORKING! Beware that torch.dot does not broadcast, only works for 1-dimensional tensor\n)\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{}),"---------------------------------------------------------------------------\n\nRuntimeError                              Traceback (most recent call last)\n\n<ipython-input-3-a29f9258176b> in <module>()\n      5     '\\nmatrix multiplication (dot)',\n      6     '\\nnumpy: ', data.dot(data),        # [[7, 10], [15, 22]]\n----\x3e 7     '\\ntorch: ', torch.dot(tensor.dot(tensor))     # 30.0. Beware that torch.dot does not broadcast, only works for 1-dimensional tensor\n      8 )\n\n\nRuntimeError: dot: Expected 1-D argument self, but got 2-D\n")),Object(o.b)("p",null,"Note that:"),Object(o.b)("p",null,"torch.dot(tensor1, tensor2) \u2192 float"),Object(o.b)("p",null,"Computes the dot product (inner product) of two tensors. Both tensors are treated as 1-D vectors."),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"tensor.mm(tensor)\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{}),"tensor([[  7.,  10.],\n        [ 15.,  22.]])\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"tensor * tensor\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{}),"tensor([[  1.,   4.],\n        [  9.,  16.]])\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"torch.dot(torch.Tensor([2, 3]), torch.Tensor([2, 1]))\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{}),"tensor(7.)\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"")))}u.isMDXComponent=!0}}]);