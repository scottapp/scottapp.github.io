(window.webpackJsonp=window.webpackJsonp||[]).push([[6],{127:function(e,t,n){"use strict";n.d(t,"a",(function(){return u})),n.d(t,"b",(function(){return d}));var r=n(0),a=n.n(r);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function p(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function c(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?p(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):p(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var i=a.a.createContext({}),l=function(e){var t=a.a.useContext(i),n=t;return e&&(n="function"==typeof e?e(t):c(c({},t),e)),n},u=function(e){var t=l(e.components);return a.a.createElement(i.Provider,{value:t},e.children)},b={inlineCode:"code",wrapper:function(e){var t=e.children;return a.a.createElement(a.a.Fragment,{},t)}},m=a.a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,p=e.parentName,i=s(e,["components","mdxType","originalType","parentName"]),u=l(n),m=r,d=u["".concat(p,".").concat(m)]||u[m]||b[m]||o;return n?a.a.createElement(d,c(c({ref:t},i),{},{components:n})):a.a.createElement(d,c({ref:t},i))}));function d(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,p=new Array(o);p[0]=m;var c={};for(var s in t)hasOwnProperty.call(t,s)&&(c[s]=t[s]);c.originalType=e,c.mdxType="string"==typeof e?e:r,p[1]=c;for(var i=2;i<o;i++)p[i]=n[i];return a.a.createElement.apply(null,p)}return a.a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},174:function(e,t,n){"use strict";n.r(t),t.default=n.p+"assets/images/403_RNN_regressor_4_0-cfb4461480c263c871cf02ddee67a119.png"},175:function(e,t,n){"use strict";n.r(t),t.default=n.p+"assets/images/403_RNN_regressor_10_0-1fdc847c8e04d78885db4b76d6202569.png"},73:function(e,t,n){"use strict";n.r(t),n.d(t,"frontMatter",(function(){return p})),n.d(t,"metadata",(function(){return c})),n.d(t,"toc",(function(){return s})),n.d(t,"default",(function(){return l}));var r=n(3),a=n(7),o=(n(0),n(127)),p={title:"403 RNN Regressor"},c={unversionedId:"ai/Docker-PyTorch-Tutorial/403_RNN_regressor",id:"ai/Docker-PyTorch-Tutorial/403_RNN_regressor",isDocsHomePage:!1,title:"403 RNN Regressor",description:"View more, visit my tutorial page//mofanpy.com/tutorials/",source:"@site/docs/ai/Docker-PyTorch-Tutorial/403_RNN_regressor.md",slug:"/ai/Docker-PyTorch-Tutorial/403_RNN_regressor",permalink:"/docs/ai/Docker-PyTorch-Tutorial/403_RNN_regressor",version:"current",sidebar:"AI",previous:{title:"402 RNN",permalink:"/docs/ai/Docker-PyTorch-Tutorial/402_RNN"},next:{title:"404 Autoencoder",permalink:"/docs/ai/Docker-PyTorch-Tutorial/404_autoencoder"}},s=[],i={toc:s};function l(e){var t=e.components,p=Object(a.a)(e,["components"]);return Object(o.b)("wrapper",Object(r.a)({},i,p,{components:t,mdxType:"MDXLayout"}),Object(o.b)("p",null,"View more, visit my tutorial page: ",Object(o.b)("a",Object(r.a)({parentName:"p"},{href:"https://mofanpy.com/tutorials/"}),"https://mofanpy.com/tutorials/"),"\nMy Youtube Channel: ",Object(o.b)("a",Object(r.a)({parentName:"p"},{href:"https://www.youtube.com/user/MorvanZhou"}),"https://www.youtube.com/user/MorvanZhou")),Object(o.b)("p",null,"Dependencies:"),Object(o.b)("ul",null,Object(o.b)("li",{parentName:"ul"},"torch: 0.1.11"),Object(o.b)("li",{parentName:"ul"},"matplotlib"),Object(o.b)("li",{parentName:"ul"},"numpy")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"import torch\nfrom torch import nn\nfrom torch.autograd import Variable\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"torch.manual_seed(1)    # reproducible\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{}),"<torch._C.Generator at 0x7f9888178930>\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"# Hyper Parameters\nTIME_STEP = 10      # rnn time step\nINPUT_SIZE = 1      # rnn input size\nLR = 0.02           # learning rate\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"# show data\nsteps = np.linspace(0, np.pi*2, 100, dtype=np.float32)\nx_np = np.sin(steps)    # float32 for converting torch FloatTensor\ny_np = np.cos(steps)\nplt.plot(steps, y_np, 'r-', label='target (cos)')\nplt.plot(steps, x_np, 'b-', label='input (sin)')\nplt.legend(loc='best')\nplt.show()\n")),Object(o.b)("p",null,Object(o.b)("img",{alt:"png",src:n(174).default})),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"class RNN(nn.Module):\n    def __init__(self):\n        super(RNN, self).__init__()\n\n        self.rnn = nn.RNN(\n            input_size=INPUT_SIZE,\n            hidden_size=32,     # rnn hidden unit\n            num_layers=1,       # number of rnn layer\n            batch_first=True,   # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n        )\n        self.out = nn.Linear(32, 1)\n\n    def forward(self, x, h_state):\n        # x (batch, time_step, input_size)\n        # h_state (n_layers, batch, hidden_size)\n        # r_out (batch, time_step, hidden_size)\n        r_out, h_state = self.rnn(x, h_state)\n\n        outs = []    # save all predictions\n        for time_step in range(r_out.size(1)):    # calculate output for each time step\n            outs.append(self.out(r_out[:, time_step, :]))\n        return torch.stack(outs, dim=1), h_state\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"rnn = RNN()\nprint(rnn)\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{}),"RNN (\n  (rnn): RNN(1, 32, batch_first=True)\n  (out): Linear (32 -> 1)\n)\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)   # optimize all cnn parameters\nloss_func = nn.MSELoss()\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"h_state = None      # for initial hidden state\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"plt.figure(1, figsize=(12, 5))\nplt.ion()           # continuously plot\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{}),"<matplotlib.figure.Figure at 0x7f982fc30c50>\n")),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"for step in range(60):\n    start, end = step * np.pi, (step+1)*np.pi   # time range\n    # use sin predicts cos\n    steps = np.linspace(start, end, TIME_STEP, dtype=np.float32)\n    x_np = np.sin(steps)    # float32 for converting torch FloatTensor\n    y_np = np.cos(steps)\n\n    x = Variable(torch.from_numpy(x_np[np.newaxis, :, np.newaxis]))    # shape (batch, time_step, input_size)\n    y = Variable(torch.from_numpy(y_np[np.newaxis, :, np.newaxis]))\n\n    prediction, h_state = rnn(x, h_state)   # rnn output\n    # !! next step is important !!\n    h_state = Variable(h_state.data)        # repack the hidden state, break the connection from last iteration\n\n    loss = loss_func(prediction, y)         # cross entropy loss\n    optimizer.zero_grad()                   # clear gradients for this training step\n    loss.backward()                         # backpropagation, compute gradients\n    optimizer.step()                        # apply gradients\n\n    # plotting\n    plt.plot(steps, y_np.flatten(), 'r-')\n    plt.plot(steps, prediction.data.numpy().flatten(), 'b-')\n    plt.draw(); plt.pause(0.05)\n")),Object(o.b)("p",null,Object(o.b)("img",{alt:"png",src:n(175).default})),Object(o.b)("pre",null,Object(o.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python"}),"")))}l.isMDXComponent=!0}}]);